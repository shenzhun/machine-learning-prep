{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "day25_model_training_using_multiple_gpus.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM7Lcw2e6dsQGAkWWpIk3lt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shenzhun/machine-learning-prep/blob/master/tensorflow/day25_model_training_using_multiple_gpus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDuo6zx7-OqJ",
        "outputId": "5e6ef124-6594-4805-9551-b8b0f80a2a3f"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "from tensorflow.keras import *"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxKZrqzE-jq0",
        "outputId": "d27d888e-528c-43c0-c7b2-ad116e237ced"
      },
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "\n",
        "if gpus:\n",
        "  try:\n",
        "    tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
        "                                                            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024),\n",
        "                                                             tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    print(e)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Physical GPU, 2 Logical GPUs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9CxmLB5_bYg",
        "outputId": "9f8f6cc4-49fa-41cb-dc1b-037ad4cebaf5"
      },
      "source": [
        "MAX_LEN = 300\n",
        "BATCH_SIZE = 32\n",
        "(x_train,y_train),(x_test,y_test) = datasets.reuters.load_data()\n",
        "x_train = preprocessing.sequence.pad_sequences(x_train,maxlen=MAX_LEN)\n",
        "x_test = preprocessing.sequence.pad_sequences(x_test,maxlen=MAX_LEN)\n",
        "\n",
        "MAX_WORDS = x_train.max()+1\n",
        "CAT_NUM = y_train.max()+1\n",
        "\n",
        "ds_train = tf.data.Dataset.from_tensor_slices((x_train,y_train)) \\\n",
        "          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n",
        "          .prefetch(tf.data.experimental.AUTOTUNE).cache()\n",
        "   \n",
        "ds_test = tf.data.Dataset.from_tensor_slices((x_test,y_test)) \\\n",
        "          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n",
        "          .prefetch(tf.data.experimental.AUTOTUNE).cache()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcrlQyBd_d_v"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "def create_model():\n",
        "  model = models.Sequential()\n",
        "\n",
        "  model.add(layers.Embedding(MAX_WORDS, 7, input_length=MAX_LEN))\n",
        "  model.add(layers.Conv1D(filters=64, kernel_size=5, activation=\"relu\"))\n",
        "  model.add(layers.MaxPool1D(2))\n",
        "  model.add(layers.Conv1D(filters=32, kernel_size=3, activation=\"relu\"))\n",
        "  model.add(layers.MaxPool1D(2))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(CAT_NUM, activation=\"softmax\"))\n",
        "  return model\n",
        "\n",
        "def compile_model(model):\n",
        "  model.compile(optimizer=optimizers.Nadam(),\n",
        "                loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=[metrics.SparseCategoricalAccuracy(), metrics.SparseTopKCategoricalAccuracy()])\n",
        "  return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dayEBIH-AeNY",
        "outputId": "b5b7a1cb-4ab7-4a76-87c5-212f181e63af"
      },
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n",
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "  model.summary()\n",
        "  model = compile_model(model)\n",
        "\n",
        "history = model.fit(ds_train, validation_data = ds_test, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 300, 7)            216874    \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 296, 64)           2304      \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 148, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 146, 32)           6176      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 73, 32)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2336)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 46)                107502    \n",
            "=================================================================\n",
            "Total params: 332,856\n",
            "Trainable params: 332,856\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "Epoch 1/10\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
            "281/281 [==============================] - 16s 21ms/step - loss: 2.3961 - sparse_categorical_accuracy: 0.3799 - sparse_top_k_categorical_accuracy: 0.7118 - val_loss: 1.6742 - val_sparse_categorical_accuracy: 0.5699 - val_sparse_top_k_categorical_accuracy: 0.7645\n",
            "Epoch 2/10\n",
            "281/281 [==============================] - 4s 15ms/step - loss: 1.5548 - sparse_categorical_accuracy: 0.6018 - sparse_top_k_categorical_accuracy: 0.7840 - val_loss: 1.5383 - val_sparse_categorical_accuracy: 0.6202 - val_sparse_top_k_categorical_accuracy: 0.7943\n",
            "Epoch 3/10\n",
            "281/281 [==============================] - 4s 15ms/step - loss: 1.2485 - sparse_categorical_accuracy: 0.6738 - sparse_top_k_categorical_accuracy: 0.8391 - val_loss: 1.5426 - val_sparse_categorical_accuracy: 0.6438 - val_sparse_top_k_categorical_accuracy: 0.8094\n",
            "Epoch 4/10\n",
            "281/281 [==============================] - 4s 15ms/step - loss: 0.9667 - sparse_categorical_accuracy: 0.7502 - sparse_top_k_categorical_accuracy: 0.9007 - val_loss: 1.7291 - val_sparse_categorical_accuracy: 0.6402 - val_sparse_top_k_categorical_accuracy: 0.7988\n",
            "Epoch 5/10\n",
            "281/281 [==============================] - 4s 15ms/step - loss: 0.7113 - sparse_categorical_accuracy: 0.8214 - sparse_top_k_categorical_accuracy: 0.9435 - val_loss: 1.9960 - val_sparse_categorical_accuracy: 0.6318 - val_sparse_top_k_categorical_accuracy: 0.8037\n",
            "Epoch 6/10\n",
            "281/281 [==============================] - 4s 15ms/step - loss: 0.5286 - sparse_categorical_accuracy: 0.8693 - sparse_top_k_categorical_accuracy: 0.9664 - val_loss: 2.3213 - val_sparse_categorical_accuracy: 0.6260 - val_sparse_top_k_categorical_accuracy: 0.8077\n",
            "Epoch 7/10\n",
            "281/281 [==============================] - 4s 15ms/step - loss: 0.4080 - sparse_categorical_accuracy: 0.9033 - sparse_top_k_categorical_accuracy: 0.9805 - val_loss: 2.5732 - val_sparse_categorical_accuracy: 0.6242 - val_sparse_top_k_categorical_accuracy: 0.8085\n",
            "Epoch 8/10\n",
            "281/281 [==============================] - 4s 15ms/step - loss: 0.3340 - sparse_categorical_accuracy: 0.9231 - sparse_top_k_categorical_accuracy: 0.9871 - val_loss: 2.8043 - val_sparse_categorical_accuracy: 0.6224 - val_sparse_top_k_categorical_accuracy: 0.8077\n",
            "Epoch 9/10\n",
            "136/281 [=============>................] - ETA: 1s - loss: 0.2862 - sparse_categorical_accuracy: 0.9325 - sparse_top_k_categorical_accuracy: 0.9913"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}