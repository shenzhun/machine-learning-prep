{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "day17_optimizers.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNA6ql6aFFjkp7nN4Ww9i9S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shenzhun/machine-learning-prep/blob/master/tensorflow/day17_optimizers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5SrBlQ6iUEQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9YbHQ54eq-m"
      },
      "source": [
        "x = tf.Variable(0.0, name = \"x\", dtype = tf.float32)\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BC8LqKXBiSzh",
        "outputId": "c8d8dfb7-e6e5-4c85-b19e-80cd48cac6c3"
      },
      "source": [
        "@tf.function\n",
        "def minimizef():\n",
        "  a = tf.constant(1.0)\n",
        "  b = tf.constant(-2.0)\n",
        "  c = tf.constant(1.0)\n",
        "\n",
        "  while tf.constant(True):\n",
        "    with tf.GradientTape() as tape:\n",
        "      y = a*tf.pow(x, 2) + b*x + c\n",
        "    \n",
        "    dy_dx = tape.gradient(y, x)\n",
        "    optimizer.apply_gradients(grads_and_vars=[(dy_dx, x)])\n",
        "\n",
        "    if tf.abs(dy_dx) < tf.constant(0.00001):\n",
        "      break\n",
        "\n",
        "    if tf.math.mod(optimizer.iterations, 100) == 0:\n",
        "      # printbar()\n",
        "      tf.print(\"step= \", optimizer.iterations)\n",
        "      tf.print(\"x = \", x)\n",
        "      tf.print(\"\")\n",
        "\n",
        "  y = a*tf.pow(x,2) + b*x + c\n",
        "  return y\n",
        "\n",
        "tf.print(\"y= \", minimizef())\n",
        "tf.print(\"x =\", x)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step=  100\n",
            "x =  0.867380381\n",
            "\n",
            "step=  200\n",
            "x =  0.98241204\n",
            "\n",
            "step=  300\n",
            "x =  0.997667611\n",
            "\n",
            "step=  400\n",
            "x =  0.999690652\n",
            "\n",
            "step=  500\n",
            "x =  0.999959\n",
            "\n",
            "step=  600\n",
            "x =  0.999994457\n",
            "\n",
            "y=  0\n",
            "x = 0.999995172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14dGmbsSv96p",
        "outputId": "b53401b2-6643-46d6-9836-6bd3f1593e0c"
      },
      "source": [
        "def f():\n",
        "  a = tf.constant(1.0)\n",
        "  b = tf.constant(-2.0)\n",
        "  c = tf.constant(1.0)\n",
        "\n",
        "  y = a*tf.pow(x,2) + b*x + c\n",
        "  return y\n",
        "\n",
        "@tf.function\n",
        "def train(epoch=1000):\n",
        "  for _ in tf.range(epoch):\n",
        "    optimizer.minimize(f, [x])\n",
        "  \n",
        "  tf.print(\"epoch = \", optimizer.iterations)\n",
        "  return f()\n",
        "\n",
        "train(1000)\n",
        "tf.print(\"y = \", f())\n",
        "tf.print(\"x = \", x)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch =  1606\n",
            "y =  0\n",
            "x =  0.99999851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUdYA3IHw7jF",
        "outputId": "09114704-0921-45e1-d4f1-81a416bb2175"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "class FakeModel(tf.keras.models.Model):\n",
        "  def __init__(self, a, b, c):\n",
        "    super(FakeModel, self).__init__()\n",
        "    self.a = a\n",
        "    self.b = b\n",
        "    self.c = c\n",
        "  \n",
        "  def build(self):\n",
        "    self.x = tf.Variable(0.0, name=\"x\")\n",
        "    self.built = True\n",
        "  \n",
        "  def call(self, features):\n",
        "    loss = self.a*(self.x)**2 + self.b*(self.x) + self.c\n",
        "    return tf.ones_like(features)*loss\n",
        "\n",
        "def myloss(y_true, y_pred):\n",
        "  return tf.reduce_mean(y_pred)\n",
        "\n",
        "model = FakeModel(tf.constant(1.0), tf.constant(-2.0), tf.constant(1.0))\n",
        "\n",
        "model.build()\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.01), loss=myloss)\n",
        "history = model.fit(tf.zeros((100,2)),\n",
        "                    tf.ones(100),\n",
        "                    batch_size=1,\n",
        "                    epochs=10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"fake_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Total params: 1\n",
            "Trainable params: 1\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 0s 823us/step - loss: 0.4930\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 0s 722us/step - loss: 0.0087\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 0s 886us/step - loss: 1.5250e-04\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 830us/step - loss: 2.6838e-06\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 0s 757us/step - loss: 4.3807e-08\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 0s 750us/step - loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 0s 712us/step - loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 0s 740us/step - loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 0s 703us/step - loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 0s 766us/step - loss: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQXoe4YYypuJ",
        "outputId": "3e0ed019-859d-4a4a-8a95-cdb077b28c0d"
      },
      "source": [
        "tf.print(\"x=\", model.x)\n",
        "tf.print(\"loss=\",model(tf.constant(0.0)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x= 0.99999851\n",
            "loss= 0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
